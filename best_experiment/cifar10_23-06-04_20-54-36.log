> cuda memory allocated: 44781056
> n_trainable_params: 11181642, n_nontrainable_params: 0
> training arguments:
>>> dataset: cifar10
>>> data_dir: data
>>> num_epoch: 200
>>> batch_size: 128
>>> resize: 256
>>> gpus: 0
>>> seed: 7890
>>> lr: 0.0001
>>> weight_decay: 0.0001
>>> clip_norm: 50
>>> default_directory: drive/app/torch/save_models
>>> optimizer: adam
>>> device: cuda:2
>>> log_name: cifar10_23-06-04_20-54-36.log
1/200 - 0.50%
[train] loss: 0.0029, acc: 36.24, err: 63.76
[test] loss: 0.0131, acc: 65.22, err: 34.78
2/200 - 1.00%
[train] loss: 0.0021, acc: 61.31, err: 38.69
[test] loss: 0.0084, acc: 75.56, err: 24.44
3/200 - 1.50%
[train] loss: 0.0017, acc: 69.37, err: 30.63
[test] loss: 0.0065, acc: 79.99, err: 20.01
4/200 - 2.00%
[train] loss: 0.0014, acc: 73.32, err: 26.68
[test] loss: 0.0054, acc: 82.72, err: 17.28
5/200 - 2.50%
[train] loss: 0.0013, acc: 76.21, err: 23.79
[test] loss: 0.0047, acc: 85.06, err: 14.94
6/200 - 3.00%
[train] loss: 0.0012, acc: 78.16, err: 21.84
[test] loss: 0.0042, acc: 86.53, err: 13.47
7/200 - 3.50%
[train] loss: 0.0011, acc: 79.70, err: 20.30
[test] loss: 0.0039, acc: 87.62, err: 12.38
8/200 - 4.00%
[train] loss: 0.0010, acc: 80.80, err: 19.20
[test] loss: 0.0036, acc: 88.43, err: 11.57
9/200 - 4.50%
[train] loss: 0.0010, acc: 82.41, err: 17.59
[test] loss: 0.0034, acc: 88.86, err: 11.14
10/200 - 5.00%
[train] loss: 0.0009, acc: 82.41, err: 17.59
[test] loss: 0.0032, acc: 89.19, err: 10.81
